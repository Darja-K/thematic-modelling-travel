{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uuuniUXTjGuH"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGjQSVRDpKn4",
    "outputId": "9e6a1534-14a9-4c9c-8ef1-4ff624bedc36"
   },
   "outputs": [],
   "source": [
    "# 1. Загрузка данных\n",
    "df = pd.read_csv('Go Russia.csv')\n",
    "\n",
    "# 2. Предварительная проверка данных\n",
    "print(\"Первые 5 строк:\")\n",
    "print(df.head())\n",
    "print(\"\\nКолонки датафрейма:\")\n",
    "print(df.columns)\n",
    "print(\"\\nИнформация о датафрейме:\")\n",
    "df.info()\n",
    "\n",
    "# 3. Обработка пропущенных значений\n",
    "df = df.dropna(subset=['Текст'])\n",
    "df['Текст'] = df['Текст'].astype(str)\n",
    "\n",
    "# 4. Рассчёт основных параметров\n",
    "df['char_length'] = df['Текст'].apply(len)  # Длина в символах\n",
    "df['word_count'] = df['Текст'].apply(lambda x: len(x.split()))  # Количество слов\n",
    "df['unique_words'] = df['Текст'].apply(lambda x: len(set(x.split())))  # Уникальные слова\n",
    "df['lexical_diversity'] = df.apply(\n",
    "    lambda x: x['unique_words'] / x['word_count'] if x['word_count'] > 0 else 0,\n",
    "    axis=1\n",
    ")  # Лексическое разнообразие\n",
    "df['avg_word_length'] = df['Текст'].apply(\n",
    "    lambda x: np.mean([len(word) for word in x.split()]) if len(x.split()) > 0 else 0\n",
    ")  # Средняя длина слова\n",
    "\n",
    "# 5. Статистика по датафрейму\n",
    "total_texts = len(df)\n",
    "avg_char_length = df['char_length'].mean()\n",
    "avg_word_count = df['word_count'].mean()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Общее количество текстов: {total_texts}\")\n",
    "print(f\"Средняя длина текста в символах: {avg_char_length:.2f}\")\n",
    "print(f\"Среднее количество слов в тексте: {avg_word_count:.2f}\")\n",
    "print(f\"Среднее количество уникальных слов: {df['unique_words'].mean():.2f}\")\n",
    "print(f\"Среднее лексическое разнообразие: {df['lexical_diversity'].mean():.4f}\")\n",
    "print(f\"Средняя длина слова: {df['avg_word_length'].mean():.2f} символов\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTNyDZFQpOjP",
    "outputId": "23ec6337-ca25-4743-9382-ecfb9e1d058b"
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download ru_core_news_sm\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"ru_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
    "russian_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609,
     "referenced_widgets": [
      "d3fa49b30c254db69d8e748aa0404ad6",
      "e5e3a9b6c862432fa523caf1fe62d5ef",
      "6480f9c00d794580bb0295baadcc62bb",
      "73205c2b18d043678c19f4c7f3fde4d5",
      "4fd941f880a549269715eeed7d1207bf",
      "1d3535262b5b4423a59e0b9b6aebea7a",
      "ff90dde1c9b148b9a9369d82ba83105d",
      "2f163a699e8c4a9c9fbe9ba187a60d63",
      "1db915ec85b447db90cdb671dc147c5d",
      "991a0ab1e82e4540b0e5a45dee6f8d75",
      "e28e9deeea024ef582909d19c38ca725",
      "3ed811300d404f5cb60b8052b0a3e773",
      "35820a85bb5746dfbe222682a1a3bf2d",
      "9f5f2cb9deef4c46b11d037b3a301fe3",
      "8911810eb0eb4e14834f77e428edc7b3",
      "88c45150971b477ab3c20af664a99ac5",
      "9e6f3e454d2d459ba051c82a087b8e42",
      "9ba2acd239144848a1949a01ef2e8686",
      "311efa943e1743419ab14a19fecc10e1",
      "62f1e78986504686a20fdd04905ffa28",
      "35d06c555dc5430bbb2894822e675cd3",
      "a02b5b9116174c29a14e7f99bf60f46c",
      "ea636139a8c14284bb49c2eb297c4501",
      "49b941ebe1884cc880afb7d7baae2ee5",
      "ef80f4e36acd43d7ad76f82cc42480a3",
      "0d65b02d28074b14a2b2e87d141dd758",
      "46bba02d30f441c88bcd3bdcb443846a",
      "15474b3b307d4303a850ea431a9b9576",
      "0891ae031cfe44eeb2d7772f035feea2",
      "ef94b529f6854e40b99d5d5356e41331",
      "0685c6f77c394bfd8862be217eb66a7b",
      "835e38d708c64b52adb573aef3d54ec7",
      "c583a0fb592b42ddb32e35a45c12bc42",
      "5d626a2fc6f84eeb9f68fc943342df27",
      "af5c3a535ced401992b81a7b8cca387a",
      "42f904037c9b471f8777c500576879b4",
      "273dcf4ef10b4204b87e8600a57e8bbe",
      "534ade4182844cf3bc22ff3369e7181e",
      "9f11cbf2c0764366afb55b87f327d8e8",
      "153d2faf2be6494b81fd80019551158c",
      "413fa55afdcb4c749cfc1935cc98105a",
      "08d822e9d2254b7fb2589ee0405fcf87",
      "0b7258f013024afea31deb07f0d38ef1",
      "473bb6db28b54b6f9c3b980a8edba272",
      "8761d2bf23b043fb92a0112c432e56fb",
      "4bc88266a0704c48b605a932adbd9b0c",
      "67d4e662e08044368a83dd6cde95ab71",
      "9e2f2ff6904646438ca5568e07a2fd39",
      "9b1f3edfba9a4a52bbf1d74d11ffde15",
      "784910f6393843fda029015697aad3e5",
      "39a5bf454bb943ac8121b02432b988ea",
      "6c4b99b0a1b44b77a7e0bedfbee35cd9",
      "781b92e80eee4bd69e09db42590d3553",
      "b5a9747767dc4cb3b804063962d74d09",
      "d56ff7d57e32458d92846adf3a6059b8",
      "91108965eef54d5db089a24238eb5236",
      "3815003be9c447f883d1eee87e2e0e3f",
      "8afa681bbf96479c9d65cfa836ab8ec5",
      "ac3eb7764ad148459726d78f49e4cb9d",
      "2c5211d88aea43998dda6204a9c00858",
      "6d2e6192a7784daea8f542f5b33582d6",
      "db5df870a716494a9512130c599818a1",
      "378f11c7e9df4f27a5c41c5187c3a9d2",
      "ef8646083f814d489e850861d56ac907",
      "7a3eb2973b7b41779340105e00ad5789",
      "5bd5649081cc4d3dbecdcee6eada2390",
      "e50953e6c3e943d99792f3e6fe83d5d3",
      "1d7569304f4c41078d852ddd9444c054",
      "7889c40f5a8b4784be977257b429e626",
      "e74caa7c6ef842b2940345fb3074a64a",
      "bfb3adbf63d8481ea08971788ec91c98",
      "ca071dc4a45547248804ff9004409a24",
      "b735c2765dc848a8b5cb028bfd6b51d5",
      "d07974a12d5a4e7fbaf78ecdcae21e48",
      "6cf212263e4b4c11a5cb892e530f064d",
      "b3f7219a43e04c59bf346e1162c88bc5",
      "0ab9559c0af849fdbecfc2ad308b17ab",
      "02d141932455474b8dd465eb19575b67",
      "9a6dda855ff643d8a435d640d53fc5fc",
      "306e8a6ed8094fd88addf36fdb1f953b",
      "a2b46ac7c8dc41319e4cb6ec3b542cc3",
      "0a6ddd8d40ea4f37b83bfcc153d4463d",
      "098d34abb30e4b7cac243a848c776887",
      "4c18b23b1e74413290fd1fc971d46c25",
      "fd2e7a274917405b9668e156f034d616",
      "453e780d336241a2a4dfddec0bedcb58",
      "7beafc10b0174898a49f4c05add1db3d",
      "0019a71832ac42c7ab9d9ea1591c76a8",
      "4b30903e34794d619a8fc26aa749206e",
      "ac60efc582d14887bd97fa4a0e8f629e",
      "74ce5630255d4ae28472bc8a3c1e11ce",
      "010f648ea9434eb38769fadaad38fc9d",
      "0538b3d4d29440fdbdc57d6dde54400c",
      "5e991426a1174b25a86f5209cd16f6fd",
      "75e4b00f92064287bcf7cb49f1fd10c0",
      "6073e934b26d4ef0a812b4056ea83234",
      "c63beedad5d44608b9234603a092f937",
      "a0c153b32d19403ab1a7006bc1054379",
      "79d5b436235d45069d3d6ef4b5611e23",
      "b42f39f95d8344858bf1f99b932777f4",
      "ab124320df724f7cb2cb30cdb76baa84",
      "7b268615d493441eab0927cf89cbaf04",
      "36668c72177d4d8a8fc7a23e915db2e7",
      "53cfce527aca4c1baca1f8ec9a9853c5",
      "7881350fc7154e8c849219a1c08bd1d6",
      "0179a0661fa64a05b46f85fad1bd7339",
      "f83f8e5ade46487e95d6a853232b875a",
      "f90e27523136438e9b7c85cc8d616656",
      "2a5f34d03f594a1caf0809a23c450034",
      "388cecfe03dd430198d03492e9b96c75",
      "b7c822882fba4024b69177fb58beafc0",
      "e8af82abfed44fd2a277ffd51f25afb8",
      "38156280732346b5a3a68f37bc576b31",
      "2cd9857e25c64a41ac7884c4c1fcf1cc",
      "97beec7cca4547cc9f8918423f7edd9f",
      "9a35a3688cfa42a59503b356720b12a7",
      "7d34606b6465429d9a5d71a79b04e277",
      "50a775a157db47bd8e12fcb2db947096",
      "18126dcd4e184d2b815ae0acb73ea049",
      "229c8e8449a64e539d6d0fa50327e96e",
      "a75d51b7801f4bb49dc147535c3beb83"
     ]
    },
    "id": "3EwpXF5GpkCF",
    "outputId": "bc25e6e4-c848-4867-808d-b42dc41aed88"
   },
   "outputs": [],
   "source": [
    "#  Функция предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "\n",
    "    # Удаление спецсимволов и цифр\n",
    "    text = re.sub(r'[^а-яё\\s]', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Токенизация и лемматизация с помощью spacy\n",
    "    doc = nlp(text)\n",
    "    lemmas = [\n",
    "        token.lemma_ for token in doc\n",
    "        if token.text not in russian_stopwords\n",
    "        and len(token.text) > 2\n",
    "        and token.is_alpha\n",
    "    ]\n",
    "\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "#  Предобработка текста\n",
    "print(\"\\nНачало предобработки текста...\")\n",
    "combined_texts = (df['Заголовок'].fillna('') + ' ' + df['Текст'].fillna(''))\n",
    "tqdm.pandas(desc=\"Предобработка текстов\")\n",
    "df['processed_text'] = combined_texts.progress_apply(preprocess_text)\n",
    "print(\"Предобработка текста завершена!\")\n",
    "\n",
    "#  Создание эмбеддингов\n",
    "print(\"\\nСоздание векторных представлений текстов...\")\n",
    "texts = df['processed_text'].tolist()\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(texts, show_progress_bar=True, batch_size=32)\n",
    "print(f\"Создано {len(embeddings)} векторных представлений размерностью {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIA7P-Fnl6Qv",
    "outputId": "919a1fea-ba91-4809-de6f-4280a6809d34"
   },
   "outputs": [],
   "source": [
    "# сравнение текстов\n",
    "print(\"\\nПример текста до обработки:\")\n",
    "print(combined_texts.iloc[0])\n",
    "print(\"\\nПример текста после обработки:\")\n",
    "print(df['processed_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnVXsqD0Hxdj"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HzQ5sIY-vYGI",
    "outputId": "b36a09d9-a943-4444-d1a5-cc65f1c08088"
   },
   "outputs": [],
   "source": [
    "# ---- ФУНКЦИЯ СИЛУЭТНОГО ГРАФИКА ----\n",
    "def plot_silhouettes(samples_silhouettes, labels, n_clusters, silhouette_avg):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = samples_silhouettes[labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = plt.cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                         0, ith_cluster_silhouette_values,\n",
    "                         facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10  # 10 for spacing between silhouette plots\n",
    "\n",
    "    ax.set_title(\"Silhouette plot\")\n",
    "    ax.set_xlabel(\"Silhouette score\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(np.arange(-0.2, 1.1, 0.2))\n",
    "    plt.show()\n",
    "\n",
    "# ---- ПОИСК ОПТИМАЛЬНОГО ЧИСЛА КЛАСТЕРОВ, СИЛУЭТНЫЕ ГРАФИКИ ----\n",
    "K = range(2, 8)\n",
    "inertias = []\n",
    "silhouette_avgs = []\n",
    "\n",
    "for k in K:\n",
    "    print(f\"\\nОбработка для {k} кластеров...\")\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette_avg = silhouette_score(embeddings, labels)\n",
    "    silhouette_avgs.append(silhouette_avg)\n",
    "    inertias.append(inertia)\n",
    "    print(f\"Кластеров: {k} | inertia: {inertia:.0f} | Silhouette avg: {silhouette_avg:.3f}\")\n",
    "\n",
    "    # Считаем силуэты для всех точек\n",
    "    samples_silhouettes = silhouette_samples(embeddings, labels)\n",
    "\n",
    "    # Визуализация силуэтного графика для данного k\n",
    "    plot_silhouettes(samples_silhouettes, labels, k, silhouette_avg)\n",
    "\n",
    "# Графики локтя и силуэта\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K, inertias, marker='o')\n",
    "plt.xlabel('Число кластеров (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Метод локтя')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K, silhouette_avgs, marker='o')\n",
    "plt.xlabel('Число кластеров (k)')\n",
    "plt.ylabel('Средний силуэт')\n",
    "plt.title('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ВЫБОР ЧИСЛА КЛАСТЕРОВ по анализу графиков\n",
    "NUM_CLUSTERS = int(input(\"\\nВведите оптимальное число кластеров на основе графиков: \"))\n",
    "\n",
    "# 4. Кластеризация с выбранным числом кластеров\n",
    "print(f\"\\nКластеризация с {NUM_CLUSTERS} кластерами...\")\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# 5. Визуализация на плоскости\n",
    "print(\"Снижение размерности с помощью t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=40)\n",
    "emb_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "df['tsne_1'] = emb_2d[:, 0]\n",
    "df['tsne_2'] = emb_2d[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(x=df['tsne_1'], y=df['tsne_2'], hue=clusters, palette='tab10', legend='full')\n",
    "plt.title('Кластеризация текстов о путешествиях')\n",
    "plt.show()\n",
    "\n",
    "# 6. Сохраняем таблицу\n",
    "df.to_csv('Go_Russia_clusters.csv', index=False)\n",
    "print(\"Результаты сохранены в Go_Russia_clusters.csv\")\n",
    "\n",
    "# 7. Просмотр примеров из каждого кластера\n",
    "print(\"\\nПримеры текстов по кластерам:\")\n",
    "for i in range(NUM_CLUSTERS):\n",
    "    cluster_size = len(df[df['cluster'] == i])\n",
    "    print(f\"\\nCluster {i} ({cluster_size} текстов):\")\n",
    "    cluster_examples = df[df['cluster'] == i]['Заголовок'].head(5).tolist()\n",
    "    for j, example in enumerate(cluster_examples, 1):\n",
    "        print(f' {j}. {example}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azkT5UC3u-VU",
    "outputId": "a1150e08-6403-45e2-e274-66eb172740c4"
   },
   "outputs": [],
   "source": [
    "!pip install stop-words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6Us5vN4uWA2O",
    "outputId": "53d1a706-233f-457d-86e4-21cc73954759"
   },
   "outputs": [],
   "source": [
    "# функция для анализа кластеров\n",
    "def show_cluster_info(df, text_col='processed_text', title_col='Заголовок', n_top_words=15):\n",
    "    russian_stop_words = get_stop_words('russian')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"АНАЛИЗ КЛАСТЕРОВ\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    cluster_stats = []\n",
    "\n",
    "    for c in sorted(df['cluster'].unique()):\n",
    "        cluster_df = df[df['cluster'] == c]\n",
    "        cluster_size = len(cluster_df)\n",
    "        cluster_stats.append((c, cluster_size))\n",
    "\n",
    "        print(f\"\\n### Кластер {c} ({cluster_size} текстов, {cluster_size/total_texts:.1%} данных):\")\n",
    "\n",
    "        # Извлекаем тексты кластера\n",
    "        cluster_texts = cluster_df[text_col].dropna().astype(str).tolist()\n",
    "\n",
    "        if not cluster_texts:\n",
    "            print('Нет текстов для анализа!')\n",
    "            continue\n",
    "\n",
    "        # Анализ ключевых слов через TF-IDF\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(max_features=500, stop_words=russian_stop_words)\n",
    "            tfidf_matrix = vectorizer.fit_transform(cluster_texts)\n",
    "            words = vectorizer.get_feature_names_out()\n",
    "            scores = tfidf_matrix.mean(axis=0).A1\n",
    "            indices = scores.argsort()[::-1][:n_top_words]\n",
    "            top_words = [words[i] for i in indices]\n",
    "\n",
    "            print(f'🔑 Ключевые слова: {\", \".join(top_words)}')\n",
    "        except ValueError:\n",
    "            print(\"⚠️ Не удалось извлечь ключевые слова (возможно, недостаточно разнообразная лексика)\")\n",
    "\n",
    "        # Примеры заголовков\n",
    "        titles = cluster_df[title_col].dropna().astype(str).tolist()[:20]\n",
    "        print(\"\\n📝 Примеры заголовков:\")\n",
    "        for i, title in enumerate(titles, 1):\n",
    "            print(f\" {i}. {title}\")\n",
    "\n",
    "    # Визуализация распределения кластеров\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    clusters, counts = zip(*sorted(cluster_stats, key=lambda x: x[0]))\n",
    "    plt.bar([str(c) for c in clusters], counts, color=plt.cm.tab10.colors[:len(clusters)])\n",
    "    plt.title('Распределение текстов по кластерам')\n",
    "    plt.xlabel('Номер кластера')\n",
    "    plt.ylabel('Количество текстов')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Вызываем функцию анализа кластеров\n",
    "show_cluster_info(df)\n",
    "\n",
    "# Дополнительный анализ: средние характеристики по кластерам\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СРЕДНИЕ ХАРАКТЕРИСТИКИ ПО КЛАСТЕРАМ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cluster_metrics = df.groupby('cluster').agg({\n",
    "    'char_length': 'mean',\n",
    "    'word_count': 'mean',\n",
    "    'lexical_diversity': 'mean',\n",
    "    'avg_word_length': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "cluster_metrics.columns = ['Кластер', 'Символы', 'Слова', 'Лекс.разнообр.', 'Ср.длина слова']\n",
    "print(cluster_metrics.round(2))\n",
    "\n",
    "# Визуализация метрик\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, metric in enumerate(['Символы', 'Слова', 'Лекс.разнообр.', 'Ср.длина слова'], 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.barplot(x='Кластер', y=metric, data=cluster_metrics, palette='tab10')\n",
    "    plt.title(f'Среднее значение: {metric}')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4F0hkbL4cr21",
    "outputId": "a05b955a-f339-4517-a64b-8bf858c5e695"
   },
   "outputs": [],
   "source": [
    "# ВЫБОР ЧИСЛА КЛАСТЕРОВ по анализу графиков\n",
    "NUM_CLUSTERS = int(input(\"\\nВведите оптимальное число кластеров на основе графиков: \"))\n",
    "\n",
    "# 4. Кластеризация с выбранным числом кластеров\n",
    "print(f\"\\nКластеризация с {NUM_CLUSTERS} кластерами...\")\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# 5. Визуализация на плоскости\n",
    "print(\"Снижение размерности с помощью t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=40)\n",
    "emb_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "df['tsne_1'] = emb_2d[:, 0]\n",
    "df['tsne_2'] = emb_2d[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(x=df['tsne_1'], y=df['tsne_2'], hue=clusters, palette='tab10', legend='full')\n",
    "plt.title('Кластеризация текстов о путешествиях')\n",
    "plt.show()\n",
    "\n",
    "# 6. Сохраняем таблицу\n",
    "df.to_csv('Go_Russia_clusters.csv', index=False)\n",
    "print(\"Результаты сохранены в Go_Russia_clusters.csv\")\n",
    "\n",
    "# 7. Просмотр примеров из каждого кластера\n",
    "print(\"\\nПримеры текстов по кластерам:\")\n",
    "for i in range(NUM_CLUSTERS):\n",
    "    cluster_size = len(df[df['cluster'] == i])\n",
    "    print(f\"\\nCluster {i} ({cluster_size} текстов):\")\n",
    "    cluster_examples = df[df['cluster'] == i]['Заголовок'].head(5).tolist()\n",
    "    for j, example in enumerate(cluster_examples, 1):\n",
    "        print(f' {j}. {example}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "64RPyyhrc_aU",
    "outputId": "f6b750a8-e7fa-4a1c-eb4d-3c0c4d047200"
   },
   "outputs": [],
   "source": [
    "# функция для анализа кластеров\n",
    "def show_cluster_info(df, text_col='processed_text', title_col='Заголовок', n_top_words=15):\n",
    "    russian_stop_words = get_stop_words('russian')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"АНАЛИЗ КЛАСТЕРОВ\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    cluster_stats = []\n",
    "\n",
    "    for c in sorted(df['cluster'].unique()):\n",
    "        cluster_df = df[df['cluster'] == c]\n",
    "        cluster_size = len(cluster_df)\n",
    "        cluster_stats.append((c, cluster_size))\n",
    "\n",
    "        print(f\"\\n### Кластер {c} ({cluster_size} текстов, {cluster_size/total_texts:.1%} данных):\")\n",
    "\n",
    "        # Извлекаем тексты кластера\n",
    "        cluster_texts = cluster_df[text_col].dropna().astype(str).tolist()\n",
    "\n",
    "        if not cluster_texts:\n",
    "            print('Нет текстов для анализа!')\n",
    "            continue\n",
    "\n",
    "        # Анализ ключевых слов через TF-IDF\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(max_features=500, stop_words=russian_stop_words)\n",
    "            tfidf_matrix = vectorizer.fit_transform(cluster_texts)\n",
    "            words = vectorizer.get_feature_names_out()\n",
    "            scores = tfidf_matrix.mean(axis=0).A1\n",
    "            indices = scores.argsort()[::-1][:n_top_words]\n",
    "            top_words = [words[i] for i in indices]\n",
    "\n",
    "            print(f'🔑 Ключевые слова: {\", \".join(top_words)}')\n",
    "        except ValueError:\n",
    "            print(\"⚠️ Не удалось извлечь ключевые слова (возможно, недостаточно разнообразная лексика)\")\n",
    "\n",
    "        # Примеры заголовков\n",
    "        titles = cluster_df[title_col].dropna().astype(str).tolist()[:20]\n",
    "        print(\"\\n📝 Примеры заголовков:\")\n",
    "        for i, title in enumerate(titles, 1):\n",
    "            print(f\" {i}. {title}\")\n",
    "\n",
    "    # Визуализация распределения кластеров\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    clusters, counts = zip(*sorted(cluster_stats, key=lambda x: x[0]))\n",
    "    plt.bar([str(c) for c in clusters], counts, color=plt.cm.tab10.colors[:len(clusters)])\n",
    "    plt.title('Распределение текстов по кластерам')\n",
    "    plt.xlabel('Номер кластера')\n",
    "    plt.ylabel('Количество текстов')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Вызываем функцию анализа кластеров\n",
    "show_cluster_info(df)\n",
    "\n",
    "# Дополнительный анализ: средние характеристики по кластерам\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СРЕДНИЕ ХАРАКТЕРИСТИКИ ПО КЛАСТЕРАМ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cluster_metrics = df.groupby('cluster').agg({\n",
    "    'char_length': 'mean',\n",
    "    'word_count': 'mean',\n",
    "    'lexical_diversity': 'mean',\n",
    "    'avg_word_length': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "cluster_metrics.columns = ['Кластер', 'Символы', 'Слова', 'Лекс.разнообр.', 'Ср.длина слова']\n",
    "print(cluster_metrics.round(2))\n",
    "\n",
    "# Визуализация метрик\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, metric in enumerate(['Символы', 'Слова', 'Лекс.разнообр.', 'Ср.длина слова'], 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.barplot(x='Кластер', y=metric, data=cluster_metrics, palette='tab10')\n",
    "    plt.title(f'Среднее значение: {metric}')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
